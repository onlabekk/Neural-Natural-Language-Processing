{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW1_NLP.ipynb","provenance":[{"file_id":"1jU0kKOQZnx4_SVupvP6GfKV3OG5Ej3_A","timestamp":1621896011000},{"file_id":"15JIcidWDAs3-Neku3Eln8nuJfWC8evOW","timestamp":1621889851806}],"collapsed_sections":["GAMaMjZeE8lH"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8eb25c55a2194680983303952647c2b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dc994f5c2eb54f15a48d1b1a01dc6891","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b0846496b4d8457f87146a8d93b17b8a","IPY_MODEL_ec58710d058647f0a40c940bde4b554d"]}},"dc994f5c2eb54f15a48d1b1a01dc6891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0846496b4d8457f87146a8d93b17b8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8483068278d0450ea331fac08be9982c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06dbd36066a94cb48ab46bce7d976d0c"}},"ec58710d058647f0a40c940bde4b554d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_deadb8fa5ff943eca8a97c57a34225cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 805kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec658138b17d4af2ad7814794d5a32ef"}},"8483068278d0450ea331fac08be9982c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"06dbd36066a94cb48ab46bce7d976d0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"deadb8fa5ff943eca8a97c57a34225cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ec658138b17d4af2ad7814794d5a32ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06fa647778a645a6b589c7d597dc0c5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_046461c20b074323a5c733692eaa14e5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5e41ef62750d47a6ad3ec8f21cbc5da4","IPY_MODEL_8f53c9eb41794c30a155f4ead6ef7278"]}},"046461c20b074323a5c733692eaa14e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e41ef62750d47a6ad3ec8f21cbc5da4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7dcd0530686a4f95b8da53025dc66ab8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b9ef777620d41cdad1be8a9515d7b8f"}},"8f53c9eb41794c30a155f4ead6ef7278":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6cd1230b18824cd5bdf5bbed69be138a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 35.6B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_786f3c1670be43f9996fd1d8419e1476"}},"7dcd0530686a4f95b8da53025dc66ab8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2b9ef777620d41cdad1be8a9515d7b8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6cd1230b18824cd5bdf5bbed69be138a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"786f3c1670be43f9996fd1d8419e1476":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1ec235711794ef48f8ca9b227a9c987":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6490ccbc7c85427287cbcee4a343e1d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b1b0dfe0d096475baaeea9dc1171b455","IPY_MODEL_7aa65b5992bb41b5b58a2d34de9cfdc3"]}},"6490ccbc7c85427287cbcee4a343e1d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1b0dfe0d096475baaeea9dc1171b455":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3f3c0b3bdd8341ce9a5d0ac987d2d91b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30f76aee837d4b52b7615c8d0ea87bbe"}},"7aa65b5992bb41b5b58a2d34de9cfdc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e07475c28d1a41ed9a9852701fd4cc73","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436k/436k [00:00&lt;00:00, 1.28MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_987258ae0815412b8e545c29a7d7e11d"}},"3f3c0b3bdd8341ce9a5d0ac987d2d91b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"30f76aee837d4b52b7615c8d0ea87bbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e07475c28d1a41ed9a9852701fd4cc73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"987258ae0815412b8e545c29a7d7e11d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"689b7e047d5f429cbdf2a256835401ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be7ba71d841041fd89244d99a1b5cd1e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_627b57e509434d27bb0e2e40131f46c5","IPY_MODEL_10fdbca389694ccdb213092e6e1a9140"]}},"be7ba71d841041fd89244d99a1b5cd1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"627b57e509434d27bb0e2e40131f46c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f3048431aa6d4939b370e5e89ac57290","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":15000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":15000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_31f25f5dca2844c7a2254a90f2af02a3"}},"10fdbca389694ccdb213092e6e1a9140":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_86905f8e926b47959476f2fd89db4886","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15000/15000 [00:49&lt;00:00, 301.71it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38566b1c5b5b45da9d29fae9d515b77b"}},"f3048431aa6d4939b370e5e89ac57290":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"31f25f5dca2844c7a2254a90f2af02a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86905f8e926b47959476f2fd89db4886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38566b1c5b5b45da9d29fae9d515b77b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19da1eca3c0a4a6085d2a5c5557a9e4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b5f4e7fb50c4475ca4a8fd6ce4a2489e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0521deb5da764e1881a011f98fb08b51","IPY_MODEL_a8afaf55772743afa5fcd2369f4808a1"]}},"b5f4e7fb50c4475ca4a8fd6ce4a2489e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0521deb5da764e1881a011f98fb08b51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_049bad6301b642f2abb4d5e8c25f79f0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":2000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c9b4aefd9b64bc9ac28f0ddcf39baac"}},"a8afaf55772743afa5fcd2369f4808a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_774a3a0f6a1d4a8399a554151a42a2f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2000/2000 [00:11&lt;00:00, 179.65it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e64d5415da1549e481adf7832dc1a7e9"}},"049bad6301b642f2abb4d5e8c25f79f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5c9b4aefd9b64bc9ac28f0ddcf39baac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"774a3a0f6a1d4a8399a554151a42a2f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e64d5415da1549e481adf7832dc1a7e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2dd5bce069174241b53c01cd8d532661":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_540fb260e7644976b2be41677bfc2023","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4aa373c58c6a47a5a2702d20047931bc","IPY_MODEL_ef05c9246e7e4777ad0f5f70ad473bc8"]}},"540fb260e7644976b2be41677bfc2023":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4aa373c58c6a47a5a2702d20047931bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5fdcbc6876014ab7bf326cb3ca3bedc8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2818a5751fe347809e2b6e8ed07d705b"}},"ef05c9246e7e4777ad0f5f70ad473bc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d75f8de83dc4edf90ce5c1ba977f7c6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:09&lt;00:00, 60.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a894d0f733c47f59929a2e91b18c67f"}},"5fdcbc6876014ab7bf326cb3ca3bedc8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2818a5751fe347809e2b6e8ed07d705b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d75f8de83dc4edf90ce5c1ba977f7c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1a894d0f733c47f59929a2e91b18c67f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ad7408896454b0881ed8f66f7ef5f58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32834375a8c142848de1404b4c34fbe4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d0d880bea7404d36a7208f5faac1f9a7","IPY_MODEL_0428664838bb4cd3adf754e11c672305"]}},"32834375a8c142848de1404b4c34fbe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0d880bea7404d36a7208f5faac1f9a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_39b76bd8a84343058972da34a7c28da2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc5d4ed72d7c45f89c1f430cb52ea81f"}},"0428664838bb4cd3adf754e11c672305":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_873f7c192db6404a885d52e47bcd604e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436M/436M [00:09&lt;00:00, 48.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2577a60212a4f7facc48ba9ec080580"}},"39b76bd8a84343058972da34a7c28da2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc5d4ed72d7c45f89c1f430cb52ea81f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"873f7c192db6404a885d52e47bcd604e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2577a60212a4f7facc48ba9ec080580":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0e2dfc596a14658b586153d7054247f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0fbd353e3af049d890343024ac7cf456","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_34ae3b4d139b4093a72e285fb4f7d006","IPY_MODEL_847610221aef4bddab24d211055de585"]}},"0fbd353e3af049d890343024ac7cf456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34ae3b4d139b4093a72e285fb4f7d006":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d7b6e6e438b442e580daeba5447263e0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4026fe04366942c796eb49ebce34375d"}},"847610221aef4bddab24d211055de585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8298015056da465a83e945f27e2cd48a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [36:20&lt;00:00, 726.68s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1beebd7bf5814fc1b403d91ca9e96ac8"}},"d7b6e6e438b442e580daeba5447263e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4026fe04366942c796eb49ebce34375d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8298015056da465a83e945f27e2cd48a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1beebd7bf5814fc1b403d91ca9e96ac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dce71090493c401c9fe17bcd01a539b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aadd501b17a44e2c90d2d5be91720d8d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8074c803a9ce4300bc0a7da1dfa5023a","IPY_MODEL_bca3ca4996dc45cf8fb59e3b0f60aa1d"]}},"aadd501b17a44e2c90d2d5be91720d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8074c803a9ce4300bc0a7da1dfa5023a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7e68e59c63584d098885a64d5a77477c","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60285a04255348aa91233d26a6409371"}},"bca3ca4996dc45cf8fb59e3b0f60aa1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71c51a1271a541418a387117efa833da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 938/938 [11:17&lt;00:00,  1.38it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b0d4b39d8cd43e6ab336c83c4697973"}},"7e68e59c63584d098885a64d5a77477c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"60285a04255348aa91233d26a6409371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71c51a1271a541418a387117efa833da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7b0d4b39d8cd43e6ab336c83c4697973":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d86af192b2f46ff89dc05c8ba9eb4c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a632ffafb5e140af994478d05c19a0bd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0affee597f2e4cc8ba54455acda19248","IPY_MODEL_dce4cf683f084356b4570e80e25023d3"]}},"a632ffafb5e140af994478d05c19a0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0affee597f2e4cc8ba54455acda19248":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_29feb1fe24b947b8b883d65e5e1ab808","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4c0ecffe7ca48e994fd5992157e96fa"}},"dce4cf683f084356b4570e80e25023d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab52381f8eea4e6b86ce047e8ea3e6be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [01:29&lt;00:00,  1.40it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a0330ff1af93463e8dc121fe7a5e5e91"}},"29feb1fe24b947b8b883d65e5e1ab808":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e4c0ecffe7ca48e994fd5992157e96fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab52381f8eea4e6b86ce047e8ea3e6be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a0330ff1af93463e8dc121fe7a5e5e91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64274f32726d454e8f9339d21f011e6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_80d21c397e90481683d639c02621c051","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5431e1d8a6844a2eb21987ea2d9b4f49","IPY_MODEL_a60a937800ef4dd7a26c7bcd1926dfd3"]}},"80d21c397e90481683d639c02621c051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5431e1d8a6844a2eb21987ea2d9b4f49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d9f12c5336e9423b8a566e27b8bfc7d5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cae000767a024627b1bda75aae149aec"}},"a60a937800ef4dd7a26c7bcd1926dfd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c64eeecf6e2048368563947a158c7578","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 938/938 [11:35&lt;00:00,  1.35it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_449d10b16bb24a1c8f35aa9a5986b10a"}},"d9f12c5336e9423b8a566e27b8bfc7d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cae000767a024627b1bda75aae149aec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c64eeecf6e2048368563947a158c7578":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"449d10b16bb24a1c8f35aa9a5986b10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f26af7ae9f42419f9d510f94e26f335e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_befe0974b2244259b787a35b5365f937","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7383533c71064302aca9210b4561bb71","IPY_MODEL_5de2f03a5bce4f0f8893014acc26a76b"]}},"befe0974b2244259b787a35b5365f937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7383533c71064302aca9210b4561bb71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_80e80f3873844f58b0e5bf4672ecbf82","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ccdbde08cd24bd5ab267e74dbd16927"}},"5de2f03a5bce4f0f8893014acc26a76b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d1ca93a6d0e842fb8d5bc6c83a7088b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [01:05&lt;00:00,  1.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d43eaeb26e7f4e92bf19bbeaae0bd6d7"}},"80e80f3873844f58b0e5bf4672ecbf82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4ccdbde08cd24bd5ab267e74dbd16927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1ca93a6d0e842fb8d5bc6c83a7088b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d43eaeb26e7f4e92bf19bbeaae0bd6d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da6bb8f21e7e4d589bc3c709848b234a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_17ba518751314284bb04f0a3ce74257f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a42a72b55b454c029d8f00e250f88e39","IPY_MODEL_b5c7bc610e9c4f299b659ea3b9be6d2e"]}},"17ba518751314284bb04f0a3ce74257f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a42a72b55b454c029d8f00e250f88e39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_daef4695c654419fb59b15cc7342002f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":938,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":938,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c61f900db1004570bd685bc7b7b01552"}},"b5c7bc610e9c4f299b659ea3b9be6d2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d144952b8b3849daa61131f50a003d8e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 938/938 [11:34&lt;00:00,  1.35it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7d29f1f69be47828751b797f1047041"}},"daef4695c654419fb59b15cc7342002f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c61f900db1004570bd685bc7b7b01552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d144952b8b3849daa61131f50a003d8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7d29f1f69be47828751b797f1047041":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf376ede7fe04c32bbc92a5c806303f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_222c665f612146afb2a21162759d1f8c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_73274d31b6de46f8ada77c614a07c240","IPY_MODEL_81541e6f2f74473fad55967d94f098c8"]}},"222c665f612146afb2a21162759d1f8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73274d31b6de46f8ada77c614a07c240":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90cc5b0ef98d4b0db4946d53e2e6722d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":125,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":125,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acd2adb229ac48e2a268563dfc8505a3"}},"81541e6f2f74473fad55967d94f098c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_27cb848d7e294bff8b51bcef634c8e14","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 125/125 [00:37&lt;00:00,  3.32it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_733dd3195fd0434d96e770a50e9df36d"}},"90cc5b0ef98d4b0db4946d53e2e6722d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acd2adb229ac48e2a268563dfc8505a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27cb848d7e294bff8b51bcef634c8e14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"733dd3195fd0434d96e770a50e9df36d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"153ed73a1dd44380be2a0e83f648aaab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_57a126f2767249a0b6893b41cc2253d5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d4e0bcfc8c824cac93fa3926be259fa5","IPY_MODEL_971c12d11c4c46f0b174d73e5c9ed2f8"]}},"57a126f2767249a0b6893b41cc2253d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4e0bcfc8c824cac93fa3926be259fa5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bbcba3390fc44911bd9833c83467fe53","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":15000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":15000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f9a233085684e50808d33376256cfac"}},"971c12d11c4c46f0b174d73e5c9ed2f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70fd75d27f9944c4948188f63155a114","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15000/15000 [05:06&lt;00:00, 48.90it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42aab79807dc4d669d6086f81f51d69b"}},"bbcba3390fc44911bd9833c83467fe53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5f9a233085684e50808d33376256cfac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70fd75d27f9944c4948188f63155a114":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"42aab79807dc4d669d6086f81f51d69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e5e68d9a912c4742a7fd3256f4b4cd18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_39f7cb29cfd64b69b017e27121c404e6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_542634377d8042f08d233f38ddbd22d9","IPY_MODEL_ccfd5b020ecb43f4b165440ae3c6f6f7"]}},"39f7cb29cfd64b69b017e27121c404e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"542634377d8042f08d233f38ddbd22d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e4e9496ca5834c85a02d9eaa3a7bf83f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":10000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_916369227dd84fbb91f616f5e10e8227"}},"ccfd5b020ecb43f4b165440ae3c6f6f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_68f28144f0f64642b7ad5d0c100a2bc3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10000/10000 [03:23&lt;00:00, 49.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9bb59ed3da924660a827a962df394370"}},"e4e9496ca5834c85a02d9eaa3a7bf83f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"916369227dd84fbb91f616f5e10e8227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68f28144f0f64642b7ad5d0c100a2bc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9bb59ed3da924660a827a962df394370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"912e7132af704963b3024cf8f9be30d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3236f13d41754856b885b91145d3bab8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_32c44d494cca4a0693c7af07b309482a","IPY_MODEL_b2c9709b84394ca8ab1e197051489dbc"]}},"3236f13d41754856b885b91145d3bab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32c44d494cca4a0693c7af07b309482a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3da58656f2364662ac44bbe463af1564","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f67ab1078e004b65912d9c3aed7c6768"}},"b2c9709b84394ca8ab1e197051489dbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_285cfaa5221e47afa8eba3bad722bf67","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/25000 [08:28&lt;00:00, 49.19it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86db312260654a5a80a156eb91afc03f"}},"3da58656f2364662ac44bbe463af1564":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f67ab1078e004b65912d9c3aed7c6768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"285cfaa5221e47afa8eba3bad722bf67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86db312260654a5a80a156eb91afc03f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69735f31b9c4440fac68f50f61a1bb22":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_713017c87a4a4895a9d94c3f8ae46348","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_75b97422710146c09cc0fbab7ac5bb7c","IPY_MODEL_e37eb2f58b5c4d3d858b53982dd176cd"]}},"713017c87a4a4895a9d94c3f8ae46348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75b97422710146c09cc0fbab7ac5bb7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba61c6a6061843d3b02484bb66be1dab","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":2000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4c40d2f950c4937bba3c220bb25accc"}},"e37eb2f58b5c4d3d858b53982dd176cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2ce334302b2e4bc494f9ac056f6c5194","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2000/2000 [03:18&lt;00:00, 10.07it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e5c4e104a944723a3012d35992e02dd"}},"ba61c6a6061843d3b02484bb66be1dab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e4c40d2f950c4937bba3c220bb25accc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ce334302b2e4bc494f9ac056f6c5194":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3e5c4e104a944723a3012d35992e02dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b401ea0ce357410888563a7da0d468e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_09a9451b9b8b41f08253356be7f4fc05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce75df1b84744566b067f58e78df5a25","IPY_MODEL_27b7a81d9b7e4db3b9952ab7fbe15949"]}},"09a9451b9b8b41f08253356be7f4fc05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce75df1b84744566b067f58e78df5a25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d15f8544a1d944b0a0ce90674fc11eb6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":8599,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":8599,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ec2e1037cf74ff3aea7d540540997c2"}},"27b7a81d9b7e4db3b9952ab7fbe15949":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ecaa2a8a030a4177b2c8b9e6214ece57","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8599/8599 [02:41&lt;00:00, 53.32it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69280274a9a74fc69ca8e021b3e0502b"}},"d15f8544a1d944b0a0ce90674fc11eb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1ec2e1037cf74ff3aea7d540540997c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ecaa2a8a030a4177b2c8b9e6214ece57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69280274a9a74fc69ca8e021b3e0502b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ruz0rsYmfS2s"},"source":["# Assignment 1 - Sentiment analysis"]},{"cell_type":"markdown","metadata":{"id":"yAvODIaynmtr"},"source":["## 0. Instructions"]},{"cell_type":"markdown","metadata":{"id":"Lzg4z9fNfS2u"},"source":["To complete the assignment please do the following  steps (all the three are requred to get the full credits): \n","\n","1. **Notebook**. Upload to Canvas a filled notebook with answers (this file). \n","Please enter the questions inside this notebook where appropriate in the designated cells.\n","\n","2. **Scripts**. In *Practical* part of this notebook you will be asked to implement different classifiers' architectures. Upload to Canvas your code which implements solutions to these parts in the form of *.py files (not *.ipynb notebooks) of the models:\n","\n","  - ``classifier_lr.py`` -  an LR based classifier\n","  - ``classifier_ffnn.py`` - a FFNN based classifier\n","  - ``classifier_rnn.py`` - an RNN based classifier\n","\n","These scripts should have the specific struction as it is shown in the baseline soultion [here](https://github.com/skoltech-nlp/filimdb_evaluation/blob/master/classifier.py). So, you should implement your ``train`` and ``classify`` functions (``pretrain`` if needed). Your model should be implemented as a special class/function in this script (be sure if you add any outer dependencies that everything is improted correctly and can be reproducable).\n","\n","  Each of these Python classifiers will be renamed to \"classifier.py\" and automatically evaluated using the evaluate.py script. Please make sure that they did not contain any dependencies which are specific to your system.\n","\n","  *Important*: to make sure everything works, please use ONLY the following software configuration (no matter which operating system you use): Anaconda 2020.07  distribution for Python 3.8 and PyTorch 1.3. The preferred way to install PyTorch is \"conda install -c pytorch pytorch\" and Torchtext is \"conda install -c pytorch torchtext\". There should be no additional libraries used: Anaconda already provides a sufficient number of them. If you need something just select from these available. Test for no the absence of dependencies by creating a virtual environment. \n","\n","3. **Shared task.** After the implementation of models' architectures you are asked to participate in the [competition](https://competitions.codalab.org/competitions/30517) to solve **Sentiment Analysis for IMDb Movie Review** task using your implemented code. \n","\n","You should use your classifier scripts from the previous part to train, validate, and generate predictions for the public and prevate test sets. For this you should use [``evaluate.py``](https://github.com/skoltech-nlp/filimdb_evaluation/blob/master/evaluate.py) script. It will produce predictions (preds.tsv) for the dataset and score them if the true labels are present. You can use these scores to evaluate your model on dev set and choose the best one. Be sure:\n","\n","1. To download the [dataset](https://github.com/skoltech-nlp/filimdb_evaluation/blob/master/FILIMDB.tar.gz) and unzip it in the same folder where ``evaluate.py`` is.\n","2. to put your ``classifier.py`` and ``evaluate.py`` scripts in the same folder. \n","\n","The models can be trained on your local machines on CPU. However, if you work in Colab you can dowload data and scripts with ``wget`` command and run them from notebook cells. \n","\n","Upload obtained TSV file with your predictions (preds.tsv) in ``.zip`` for the best results on the dev set using LR, FFNN, and RNN  respectively to the public leaderboard of the competition. \n","\n","  *Important*: You have to upload predictions based on LR model in the sub-task for LR (https://competitions.codalab.org/competitions/25623), predictions based on FFNN model in the sub-task for FFNN (https://competitions.codalab.org/competitions/25623), and predictions based on RNN model in the sub-task for RNN (https://competitions.codalab.org/competitions/25623). So in each track there is a fair competition (only the same models are compared). Your scores will not be taken into account if you submit it in the wrong sub-task, e.g. LR preditions to FFNN or RNN sub-task!\n","\n","Please, provide here in the notebook your user name in Codalab competition that we can recognize you in the leaderboard.\n"]},{"cell_type":"markdown","metadata":{"id":"9bSH5KGk_mSi"},"source":["**YOUR USERNAME IN THE CODALAB LEADERBOARD:**"]},{"cell_type":"markdown","metadata":{"id":"2N4HkgCkGrrJ"},"source":["```\n","\n","ENTER HERE\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"NUNk5y8KfS2v"},"source":["## 1. Theoretical part"]},{"cell_type":"markdown","metadata":{"id":"_6PvHj42-id6"},"source":["This part contains some questions about the models and concepts."]},{"cell_type":"markdown","metadata":{"id":"pVvCWmBnfS2v"},"source":["### 1.1 Logistic Regression\n","\n","Let us introduce the following notation:\n","\n","$(x_{\\{1\\}}, y_{\\{1\\}}), \\ldots, (x_{\\{N\\}}, y_{\\{N\\}})$ --- train set of size N, \n","\n","$x_{\\{i\\}} \\in\\mathbb{R}^M$ --- feature vector of the $i^{th}$ sample from train set, $M$ --- number of features, \n","\n","$y_{\\{i\\}} \\in \\{0, 1\\}$ --- label (class) of the $i^{th}$ sample, \n","\n","$w\\in\\mathbb{R}^{M+1}$ --- weight vector in LogReg.\n","\n","_**NB:**_ linear transofrmations on $x_{\\{i\\}}$ is as follows: \n","$$\n","w_0 + w^Tx_{\\{i\\}} = w_0+w_1*x_{\\{i\\},1}+\\ldots+w_M*x_{\\{i\\},M},\n","$$\n","\n","where $w_0$ stands for intercept term (bias).\n","\n","For the convenience of implementation we will set $x_{\\{i\\},0} = 1$. In other words, we will add 1 to vectors $x_{\\{i\\}}$. Therefore, linear transformations will be the following:\n","\n","$$w_0*1+w_1*x_{\\{i\\},1}+\\ldots+w_M*x_{\\{i\\},M} \\equiv w^T[1;x_{\\{i\\}}]$$\n"]},{"cell_type":"markdown","metadata":{"id":"qcXpETUCfS2v"},"source":["1. Find the derivative of the sigmoid function $\\sigma(z)$ and express it in terms of sigmoid, considering $z$ to be scalar \n","$$ \n","\\sigma(z) = {\\frac {1}{1+e^{-z}}}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"X9-cdpc_VQwh"},"source":["\\begin{aligned}\n","\\frac{d}{d z} \\sigma(z) &=\\frac{d}{d z}\\left[\\frac{1}{1+e^{-z}}\\right] \\\\\n","&=\\frac{d}{d z}\\left(1+\\mathrm{e}^{-z}\\right)^{-1} \\\\\n","&=-\\left(1+e^{-z}\\right)^{-2}\\left(-e^{-z}\\right) \\\\\n","&=\\frac{e^{-z}}{\\left(1+e^{-z}\\right)^{2}} \\\\\n","&=\\frac{1}{1+e^{-z}} \\cdot \\frac{e^{-z}}{1+e^{-z}} \\\\\n","&=\\frac{1}{1+e^{-z}} \\cdot \\frac{\\left(1+e^{-z}\\right)-1}{1+e^{-z}} \\\\\n","&=\\frac{1}{1+e^{-z}} \\cdot\\left(\\frac{1+e^{-z}}{1+e^{-z}}-\\frac{1}{1+e^{-z}}\\right) \\\\\n","&=\\frac{1}{1+e^{-z}} \\cdot\\left(1-\\frac{1}{1+e^{-z}}\\right) \\\\\n","&=\\sigma(z) \\cdot(1-\\sigma(z))\n","\\end{aligned}"]},{"cell_type":"markdown","metadata":{"id":"csKwntaZfS2w"},"source":["2. Prove that:  \n","\n","$$ \\sigma(-z) = 1 - \\sigma(z)$$"]},{"cell_type":"markdown","metadata":{"id":"hMC5ZgEr4DVs"},"source":["LHS:\n","$$ \\sigma(-z)=\\frac{1}{1+e^{z}} $$\n","RHS:\n","$$ 1-\\sigma(z)=1-\\frac{1}{1+e^{-z}}=1-\\frac{e^z}{e^z+1}=\\frac{1}{e^z+1} $$"]},{"cell_type":"markdown","metadata":{"id":"ABAzFw-5fS2w"},"source":["3. Write out the formula of hypothesis $h_w(x)$ for logistic regression."]},{"cell_type":"markdown","metadata":{"id":"D0kwSKhNz7NG"},"source":["$$ h_w(x)=\\frac{1}{1+e^{-w_0-w^Tx}} $$"]},{"cell_type":"markdown","metadata":{"id":"Ez2NUTftfS2x"},"source":["4. Plot the values of Binary Cross-Entropy error function for one sample from positve class and one sample from negative, depending on the logreg output $\\hat y=h_w(x)$. What the loss function value will be equal to, given zero weights (right after the initialization)?\n","$$ bce(y, \\hat y)= -y \\log \\hat y - (1-y) \\log (1 - \\hat y)$$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9yfrepwWyml","executionInfo":{"status":"ok","timestamp":1621896950862,"user_tz":-180,"elapsed":708,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"23f2cfc6-f2df-4891-ef7e-8abe94661dca"},"source":["!wget https://drive.google.com/file/d/1xy8emkVUni8yZgUY17zr_juRTOJLN9Lq/view?usp=sharing"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-24 22:55:49--  https://drive.google.com/file/d/1xy8emkVUni8yZgUY17zr_juRTOJLN9Lq/view?usp=sharing\n","Resolving drive.google.com (drive.google.com)... 74.125.142.139, 74.125.142.138, 74.125.142.100, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.142.139|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘view?usp=sharing.1’\n","\n","view?usp=sharing.1      [ <=>                ]  71.26K  --.-KB/s    in 0.03s   \n","\n","2021-05-24 22:55:49 (2.58 MB/s) - ‘view?usp=sharing.1’ saved [72972]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"LBq7v4wMWcLK","executionInfo":{"status":"ok","timestamp":1621896950863,"user_tz":-180,"elapsed":27,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"5c0bfb38-858d-4612-9201-261623b116a2"},"source":["from IPython.display import Image\n","Image('photo.jpg')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"photo.jpg","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"7mff_BTFfS2x"},"source":["5. Calculate gradient for cost function $\\nabla_w L(w, x_{\\{1\\}},\\ldots,x_{\\{N\\}})$ for binary (2 class) logistic regression. As evaluation function use cross-entropy with l2 regularization:\n","$$ L(w,x_{\\{1\\}},\\ldots,x_{\\{N\\}}) = - \\frac1{N} \\sum_{i=1}^N(y_{\\{i\\}} \\log h_w(x_{\\{i\\}}) + (1 - y_{\\{i\\}}) \\log (1 - h_w(x_{\\{i\\}}))) + \\alpha\\sum_{j=1}^M(w_j)^2$$"]},{"cell_type":"markdown","metadata":{"id":"zYvO0rTCwk9V"},"source":["\\begin{array}{c}\n","\\frac{\\partial L}{\\partial w_{0}}=\\frac{1}{N} \\sum_{k=1}^{N} y_{k} \\frac{-e^{-\\left(w_{0}+\\mathbf{w}^{T} \\mathbf{x}_{k}\\right)}}{1+e^{-\\left(w_{0}+w^{2}\\right.} x_{\\left.k_{k}\\right)}}+\\left(1-y_{k}\\right) \\frac{e^{w_{0}+w^{T} x_{k}}}{1+e^{w_{0}+w^{T} x_{k}}}=\\frac{1}{N} \\sum_{k=1}^{N}\\left(1-y_{k}\\right) h_{w}\\left(\\mathbf{x}_{k}\\right)-y_{k}\\left(1-h_{w}\\left(\\mathbf{x}_{k}\\right)\\right)=\\frac{1}{N} \\sum_{k=1}^{N} h_{w}\\left(\\mathbf{x}_{k}\\right)-y_{k} \\\\\n","\\frac{\\partial L}{\\partial w_{i}}=\\frac{1}{N} \\sum_{k=1}^{N}\\left[y_{k} \\frac{-x_{k i} e^{-\\left(w_{0}+w^{T} x_{k}\\right)}}{1+e^{-\\left(w_{0}+\\mathbf{w}^{T} x_{k}\\right)}}+\\left(1-y_{k}\\right) \\frac{x_{k i} e^{w_{0}+w^{T} x_{k}}}{1+e^{w_{0}+w^{T} x_{k}}}\\right]+2\\alpha\\sum_{j=1}^Mw_j=\\frac{1}{N} \\sum_{k=1}^{N}\\left[x_{k i}\\left(1-y_{k}\\right) h_{w}\\left(\\mathbf{x}_{k}\\right)-x_{k i} y_{k}\\left(1-h_{w}\\left(\\mathbf{x}_{k}\\right)\\right)\\right]+2\\alpha\\sum_{j=1}^Mw_j= \\\\\n","=\\frac{1}{N} \\sum_{k=1}^{N}\\left[\\left(h_{w}\\left(\\mathbf{x}_{k}\\right)-y_{k}\\right) x_{k}\\right]+2\\alpha\\sum_{j=1}^Mw_j\n","\\end{array}"]},{"cell_type":"markdown","metadata":{"id":"cLe0ibSmfS2y"},"source":["_**NB:**_ Regularization component $\\sum_{j=1}^M(w_j)^2$ does not incluse $w_0$, as it is responsible for overall shift only. It may be of any value, whereas $L_2$ regularization seeks to minimmize $w_i$ values."]},{"cell_type":"markdown","metadata":{"id":"r2X9ibD2fS2y"},"source":["6. Write out the formula for the update of vector $w$ with parameters using stochastic gradient descent optimization"]},{"cell_type":"markdown","metadata":{"id":"Th2XYRM6UfKz"},"source":["$$ w_{i+1} = w_{i} - \\eta \\nabla_{w}L $$"]},{"cell_type":"markdown","metadata":{"id":"RBMGC6UCfS2z"},"source":["7. Prove that binary cross-entropy evaluation function for binary logistic regression has the only one minimum"]},{"cell_type":"markdown","metadata":{"id":"q1hSj9hSd_AO"},"source":["For convex function any minimum is a global minimum. The function is convex as its Hessian matrix (matrix of second-order derivatives) is positive semi-definite for all possible values of w.\n"]},{"cell_type":"markdown","metadata":{"id":"F6fMOgMrfS2z"},"source":["8. Show that minimization of Binary Cross Entropy loss function for logistic regression is equivalent to the following function (sum over samples and regularization component is omitted):\n","$$ softplus(-tw^Tx),$$\n","\n","where\n","\n","$$\n","softplus(x)=log(1+e^x)$$\n","\n","$$t=2y-1 \\in \\{-1+1\\}$$\n"]},{"cell_type":"markdown","metadata":{"id":"UZsBh81efS20"},"source":["### 1.2 Feed-forward Neural Network\n","\n","Let use the fllowing notation:\n","\n","$(x_{\\{1\\}}, y_{\\{1\\}}), \\ldots, (x_{\\{N\\}}, y_{\\{N\\}})$ --- train set of size $N$\n","\n","$x_{\\{i\\}} \\in\\mathbb{R}^M$, where $i$ is the review index, \n","\n","$M=s^{(0)}$ --- number of features or dictionary size, \n","\n","$y_{\\{i\\}} \\in \\{0, 1\\}$, $s^{(l)}$ - number of neurons in the layer $l$, \n","\n","$W^{(l)}$ --- parameter matrix of $l^{th}$ layer of size $s^{l} \\times (s^{l-1}+1)$ (as we add bias), where\n","\n","$l=\\{1,2,\\cdots,L\\}$, $L$ --- number of layers (number of hidden layers is equal to $L-1$)\n","\n","\n","Feed-forward Neural Network example with two layers (one hidden layer):\n","\n","![img](http://panchenko.me/figures/nn.jpg)\n","\n","\n","Feed-forward propagation:\n","\n","$a^{(0)} = x_{\\{i\\}} $\n","\n","$z^{(1)} = W^{(1)} [1, a^{(0)}] $\n","\n","$a^{(1)} = tanh(z^{(1)})$\n","\n","$z^{(2)} = W^{(2)}[1, a^{(1)}] $\n","\n","$a^{(2)} = softmax(z^{(2)}) $\n","\n","\n","Backpropagation:\n","..."]},{"cell_type":"markdown","metadata":{"id":"En4NpSUhfS20"},"source":["1. Calculate the derivative for $\\tanh(z)$ function and express it in terms of $tanh(z)$, considering $z$ to be a scalar. Transform your answer, so that the exponent will be used only once while computing $\\tanh(z)$ and its derivative.\n","$$ \\tanh(z) = {\\frac {e^{z}-e^{-z}}{e^{z}+e^{-z}}}$$\n"]},{"cell_type":"markdown","metadata":{"id":"--AyukXvePgN"},"source":["\\begin{aligned}\n","\\frac{d}{d z}\\left(\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}\\right) &=\\frac{e^{z}+e^{-z}}{\\left(e^{z}+e^{-z}\\right)^{2}} d\\left(e^{z}-e^{-z}\\right)-\\frac{e^{z}-e^{-z}}{\\left(e^{z}+e^{-z}\\right)^{2}} d\\left(e^{z}+e^{-z}\\right) \\\\\n","&=\\frac{\\left(e^{z}+e^{-z}\\right)\\left(e^{z}+e^{-z}\\right)}{\\left(e^{z}+e^{-z}\\right)^{2}}-\\frac{\\left(e^{z}-e^{-z}\\right)\\left(e^{z}-e^{-z}\\right)}{\\left(e^{z}+e^{-z}\\right)^{2}} \\\\\n","&=\\frac{\\left(e^{z}+e^{-z}\\right)^{2}-\\left(e^{z}-e^{-z}\\right)^{2}}{\\left(e^{z}+e^{-z}\\right)^{2}} \\\\\n","&=1-\\left(\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}\\right)^{2} \\\\\n","&=1-\\tanh (z)^{2}\n","\\end{aligned}"]},{"cell_type":"markdown","metadata":{"id":"CxWaZeWkfS20"},"source":["2. Write out the cross entropy loss function $L(W^{(1)}, \\ldots, W^{(L)},x_{\\{1\\}},\\ldots,x_{\\{N\\}})$ for neural network with one hidden layer ($L=2$), and then generalize it for neural network with $L-1$ hidden layers and for multiclass classification (with $K$ classes). Use $\\tanh(z)$ activation function for hidden layer,  $softmax(z)$ for output layer."]},{"cell_type":"markdown","metadata":{"id":"oc6JXGT1C4aH"},"source":["\\begin{array}{c}\n","\\mathbf{a}_{i}^{0}=\\mathbf{x}_{i} \\in \\mathbb{R}^{d} \\\\\n","\\mathbf{z}_{i}^{1}=W^{1} \\mathbf{a}_{i}^{0} \\\\\n","\\mathbf{a}_{i}^{1}=\\tanh \\mathbf{z}_{i}^{1} \\in \\mathbb{R}^{h} \\\\\n","\\mathbf{z}_{i}^{2}=W^{2} \\mathbf{a}_{i}^{0} \\in \\mathbb{R}^{K} \\\\\n","\\mathbf{p}_{i}=\\operatorname{softmax}\\left(\\mathbf{z}_{i}^{2}\\right) \\\\\n","\\mathcal{L}\\left(W^{1}, W^{2}, \\mathbf{x}_{1}, \\ldots, \\mathbf{x}_{N}\\right)=\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=0}^{K-1}\\left[y_{i}=j\\right] \\log p_{i j}\n","\\end{array}"]},{"cell_type":"markdown","metadata":{"id":"lIqpdpZafS21"},"source":["3. Demonstrate that $softmax(z+c)=softmax(z)$, where ${c}$ -- vector with equal components"]},{"cell_type":"markdown","metadata":{"id":"S59WE5IEBEDx"},"source":["$$ softmax(\\mathbf{z}+\\mathbf{c})_{i}=\\frac{e^{z_{i}+c}}{\\sum_{j=1}^{k} e^{z_{j}+c}}=\\frac{e^{z_{i}} \\cdot e^{c}}{\\sum_{j=1}^{k} e^{z_{j}} \\cdot e^{c}}=softmax(\\mathbf{z})_{i} $$"]},{"cell_type":"markdown","metadata":{"id":"pVf40D4CfS21"},"source":["4. How many parameters does the neural network have? Inputs vectors size is $M$, output vectors size is $K$ and the number of neurons is $H$."]},{"cell_type":"markdown","metadata":{"id":"rEHsiVzuESVl"},"source":["MH+HK parameters for network with one hidden layer of dimensionality H."]},{"cell_type":"markdown","metadata":{"id":"sFr0mrLGfS21"},"source":["5. Provide the formula for the $\\delta^{(L)}$ --- gradient of loss function based on pre-activation on the last layer. $z^{(L)}$."]},{"cell_type":"markdown","metadata":{"id":"yYTXpg9XE3MG"},"source":["$ \\begin{array}{c}\n","\\delta^{(L)}=\\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\frac{\\partial \\mathcal{L}}{\\partial a^{(L)}} \\\\\n","a^{(L)}=\\operatorname{softmax}\\left(z^{(L)}\\right) \\\\\n","\\operatorname{softmax}\\left(x_{i}\\right)=\\frac{e^{x_{i}}}{\\sum_{j=1}^{n} e^{x_{j}}} \\\\\n","\\frac{\\partial}{\\partial x_{k}} \\operatorname{softmax}\\left(x_{i}\\right)=\\left\\{\\begin{array}{ll}\n","\\operatorname{softmax}\\left(x_{i}\\right)\\left(1-\\operatorname{softmax}\\left(x_{i}\\right)\\right), & \\text { if } i=k \\\\\n","\\operatorname{softmax}\\left(x_{i}\\right) \\operatorname{softmax}\\left(x_{k}\\right), & \\text { if } i \\neq k\n","\\end{array}\\right.\n","\\end{array} $"]},{"cell_type":"markdown","metadata":{"id":"Jeitmu4MfS22"},"source":["6. Provide the formula for $\\delta^{(l)}$ --- gradient of loss function on $z^{(l)}$ through $\\delta^{(l+1)}$."]},{"cell_type":"markdown","metadata":{"id":"_XunrAV4D9a_"},"source":["\\begin{array}{c}\n","a^{(l)}=g^{(l)}\\left(z^{(l)}\\right) \\\\\n","z^{(l+1)}=W^{(l+1)} a^{(l)}+b^{(l+1)} \\\\\n","\\frac{\\partial \\mathcal{L}}{\\partial a^{(l)}}=\\frac{\\partial z^{(l+1)}}{\\partial a^{(l)}} \\delta^{(l+1)}=\\left\\{W^{(l+1)}\\right\\}^{T} \\delta^{(l+1)} \\\\\n","\\delta^{(l)}=\\frac{\\partial a^{(l)}}{\\partial z^{(l)}}\\left\\{W^{(l+1)}\\right\\}^{T} \\delta^{(l+1)}\n","\\end{array}"]},{"cell_type":"markdown","metadata":{"id":"tGaHY82XfS22"},"source":["7. Provide the formula for $\\nabla_{W^{(l)}} L$ --- gradient of loss function on weights $W^{(l)}$, using $\\delta^{(l)}$."]},{"cell_type":"markdown","metadata":{"id":"7mpYCxguEFYk"},"source":["$$ \\nabla_{W^{(l)}} \\mathcal{L}=\\frac{\\partial z^{(l)}}{\\partial W^{(l+1)}} \\delta^{(l)} $$"]},{"cell_type":"markdown","metadata":{"id":"nlGboOIsDWMc"},"source":["### 1.3 Word Embeddings"]},{"cell_type":"markdown","metadata":{"id":"h9iZgfTLDblx"},"source":["1. Write down objective functions of the Skip-Gram word embedding models assuming negative sampling (SGNS)."]},{"cell_type":"markdown","metadata":{"id":"3lyiq9QAILkc"},"source":["\\begin{aligned}\n","\\mathcal{L}(\\theta) &=\\log P(+\\mid t, c)+\\sum_{i=1}^{k} \\log P\\left(-\\mid t, n_{i}\\right)=\\\\\n","&=\\log \\sigma(c \\cdot t)+\\sum_{i=1}^{k} \\log \\sigma\\left(-n_{i} \\cdot t\\right)\n","\\end{aligned}"]},{"cell_type":"markdown","metadata":{"id":"_cCZFK2uD4ab"},"source":["2. Write down derivatives with respect to the parameters (weights) of this loss function."]},{"cell_type":"markdown","metadata":{"id":"5FP3671iWt6l"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"cgvEXyFkD71S"},"source":["### 1.4 Recurrent Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"HJHpyXc788rZ"},"source":["#### 1.4.1 Computing probability"]},{"cell_type":"markdown","metadata":{"id":"F55q1rNT9Bqj"},"source":["Consider a sequence $x_1, x_2, ..., x_T$, where $x_i$ is an index of token in the vocabulary $V$ and a two-layer language model based on the LSTM neural network. Let's assume that this network generates an estimation $\\hat{y_i}[w] = \\hat{P}(x_1, ..., x_{i-1})$ of probability that token $w$ follows the sequence of tokens $x_1, ..., x_{i-1}$. "]},{"cell_type":"markdown","metadata":{"id":"QtsD_DbMAgRF"},"source":["1. Write formulas for the forward pass of this network: how to estimate the $\\hat{y_i}[w] = \\hat{P}(x_1, ..., x_{i-1})$? For simplicity, write first formulas for the individual layers, then use them to write the full formula for the forward pass.\n"]},{"cell_type":"markdown","metadata":{"id":"tI0iXNyZJ8Mf"},"source":["\\begin{array}{c}\n","h_{i}=g\\left(U h_{i-1}+W w\\right) \\\\\n","\\hat{y}_{i}=f\\left(V h_{i}\\right)\n","\\end{array}"]},{"cell_type":"markdown","metadata":{"id":"EuO1B4I_A7oj"},"source":["2. How to estimate the probability of a sequence of tokens $x_1, x_2, ..., x_T$ ie what is the probability of $\\hat{P}(x_1,...,x_T)$?"]},{"cell_type":"markdown","metadata":{"id":"YvnklPe5KEU_"},"source":["1) Initialize RNN hidden state \n","$h_0$ and weights $U, W, and$  $V$.\n","\n","2) Apply RNN sequentially to tokens $x_1, x_2, ..., x_T$ to estimate conditional probabilities from the formula above.\n","\n","3) Multiply resulting estimates."]},{"cell_type":"markdown","metadata":{"id":"lJcuTLzT8bCT"},"source":["#### 1.4.2 Vanishing gradient problem\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8fVi8dab8y7Q"},"source":["What is the vanishing / exploiding gradient problem in Elman recurrent neural networks? Write down update equations for Elman RNN and explain what is causing the vanishing / exploiding gradient issue."]},{"cell_type":"markdown","metadata":{"id":"2zx-QoNjKkmJ"},"source":["\\begin{array}{c}\n","h_{i}=g\\left(U h_{i-1}+W x_{i}\\right) \\\\\n","y_{i}=f\\left(V h_{i}\\right)\n","\\end{array}\n","\n","If the derivatives are large then the gradient will increase exponentially as we propagate down the model until they eventually explode, and this is what we call the problem of exploding gradient."]},{"cell_type":"markdown","metadata":{"id":"52oJ7vpS85ql"},"source":["How does LSTM help prevent the vanishing (and exploding) gradient problem in a recurrent neural network? Write down the equations of LSTM and explain how technically this schema is better than the Elman recurrent neural networks."]},{"cell_type":"markdown","metadata":{"id":"54R7PjWHKza-"},"source":["\\begin{array}{c}\n","\\mathbf{z}^{t}=g\\left(W_{\\mathbf{z}} \\mathbf{x}^{t}+R_{\\mathbf{z}} \\mathbf{y}^{t-1}+\\mathbf{b}_{\\mathbf{z}}\\right) \\\\\n","\\mathbf{i}^{t}=\\sigma\\left(W_{i} \\mathbf{x}^{t}+R_{i} \\mathbf{y}^{t-1}+p_{i} \\odot \\mathbf{c}^{t-1}+\\mathbf{b}_{i}\\right) \\\\\n","\\mathbf{f}^{t}=\\sigma\\left(W_{f} \\mathbf{x}^{t}+R_{f} \\mathbf{y}^{t-1}+p_{f} \\odot \\mathbf{c}^{t-1}+\\mathbf{b}_{f}\\right) \\\\\n","\\mathbf{c}^{t}=\\mathbf{z}^{t} \\odot \\mathbf{i}_{t}+\\mathbf{c}^{t-1} \\odot \\mathbf{f}_{t} \\\\\n","\\mathbf{o}^{t}=\\sigma\\left(W_{o} \\mathbf{x}^{t}+R_{o} \\mathbf{y}^{t-1}+p_{o} \\odot \\mathbf{c}^{t-1}+\\mathbf{b}_{o}\\right) \\\\\n","\\mathbf{y}_{t}=h\\left(\\mathbf{c}^{t}\\right) \\odot \\mathbf{o}^{t}\n","\\end{array}\n","\n","LSTM decouples cell state (typically denoted by c ) and hidden layer/output (typically denoted by h ), and only do additive updates to c , which makes memories in c more stable. Thus the gradient flows through c is kept and hard to vanish (therefore the overall gradient is hard to vanish).\n","\n","The LSTM architecture makes it easier for the RNN to preserve information over many timesteps\n","–e.g. if the forget gate is set to remember everything on ever timestep, then the info in the cell is preserved indefinitely.\n","\n","LSTM doesn’t guarantee that there is no vanishing/exploding gradient, but it does provide an easier way for the model to learn long-term dependencies."]},{"cell_type":"markdown","metadata":{"id":"UpXXnIzRfS22"},"source":["## 2. Practical part\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lc_4EzxUHdE7"},"source":["The goal of this part is to implement text classifiers based on logistic regression (LR), feed-forward neural netword (FFNN) or recurrent neural network (RNN) where pre-trained word embeddings are used as features. For LR and FFNN you need to simply average word embeddings of a sentence (perform average pooling of word vectors) and they apply the LR/FFNN to the output representation. In case of RNN you feed one embedding per input token."]},{"cell_type":"markdown","metadata":{"id":"LSiy-wH9n-7A"},"source":["### 2.1 Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"w0CC3azwrvHk"},"source":["2.1.1 Implementation of the model "]},{"cell_type":"markdown","metadata":{"id":"qpUK_zx_oQGb"},"source":["The goal of this section to implement using **pytorch** a text categorization model using logistic regression. Following the steps below, you can complete corresponding parts in your ``classifier_lr.py`` script and apply the code for sentiment classification task. \n","\n","**Important**: You are not expected to implement logistic regression training from scratch in this (updated) version of the task to get full scores. You are free to use optimization package of pytorch. The implementations in this assignment could and should be based on the models from the second and third seminars (and their variants by you). "]},{"cell_type":"markdown","metadata":{"id":"dx2Yv90YfS23"},"source":["To implement the model, you can follow the steps below. \n","\n","1. Load the dataset, preprocess and tokenize it. Build a dictionary with unique tokens from the train set.\n","\n","2. To train our logistic regression, our train and test data should be converted to matrices of size $N * M$ ($N$ -- number of reviews, $M$ -- feature). You can use either bag-of-words feature representation, in this case features are words or you can use word embeddings as the initial embedding matrix. In the latter case, first, load embeddings from the disk, then select the correct subset of embeddings for the words that are actually present in the data, and finally setting the Embedding layer’s weight matrix as the loaded\n","subset.\n","\n","3. Add a sigmoid function.\n","\n","4. Initialization. Write weights initialization function.\n","\n","5. Forward pass. Write a function that compute the objective function of logistic regression.\n","\n","6. Training loop. Write the function that makes a gradient descent. It is recommended to use mini-batch gradient descent: split your train data to mini-batches (100-500) samples, on each iteration calculate the gradient not for all train set, but on the current batch only. It will speed up one iterqtion computation time and the model will converge faster.\n"," "]},{"cell_type":"code","metadata":{"id":"00sVbReg0C_d"},"source":["!wget https://github.com/skoltech-nlp/filimdb_evaluation/raw/master/FILIMDB.tar.gz\n","!tar -zxvf FILIMDB.tar.gz\n","!mv -t . FILIMDB/*\n","!rm -rf FILIMDB\n","!pip install transformers -qq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTjBAG6v0DIC"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, precision_score, recall_score, f1_score\n","from torchtext.data.utils import get_tokenizer\n","from collections import Counter\n","from torchtext.vocab import Vocab\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch import optim\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm as tqdm_notebook\n","from tqdm import tqdm\n","from IPython.display import display, clear_output\n","from datetime import datetime\n","from torch.utils.tensorboard import SummaryWriter\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","from typing import List, Any\n","from time import time\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","import nltk\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer\n","import transformers\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uxPTT61BbWU"},"source":["nltk.download('wordnet')\n","nltk.download('stopwords')\n","\n","wordnet_lemmatizer = WordNetLemmatizer()\n","tokenizer = RegexpTokenizer(r'[a-z]+')\n","stop_words = set(stopwords.words('english'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzNfrkFwBbgC"},"source":["def preprocess(document):\n","    document = document.lower()   \n","    words = tokenizer.tokenize(document)   \n","    words = [w for w in words if w not in stop_words]    \n","    for pos in [wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV]:    \n","        words = [wordnet_lemmatizer.lemmatize(x, pos) for x in words]\n","    return \" \".join(words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XoqlnA9P0DSk"},"source":["train_texts = pd.read_csv(\"train.texts\", sep=\"\\n\", header=None)\n","train_labels = pd.read_csv(\"train.labels\", sep=\"\\n\", header=None)\n","train = pd.concat([train_texts, train_labels], ignore_index=True, axis=1)\n","train.columns = [\"text\", \"label\"]\n","\n","dev_texts = pd.read_csv(\"dev.texts\", sep=\"\\n\", header=None)\n","dev_labels = pd.read_csv(\"dev.labels\", sep=\"\\n\", header=None)\n","dev = pd.concat([dev_texts, dev_labels], ignore_index=True, axis=1)\n","dev.columns = [\"text\", \"label\"]\n","\n","dev_b_texts = pd.read_csv(\"dev-b.texts\", sep=\"\\n\", header=None)\n","dev_b_labels = pd.read_csv(\"dev-b.labels\", sep=\"\\n\", header=None)\n","dev_b = pd.concat([dev_b_texts, dev_b_labels], ignore_index=True, axis=1)\n","dev_b.columns = [\"text\", \"label\"]\n","\n","test = pd.read_csv(\"test.texts\", sep=\"\\n\", header=None)\n","test.columns = [\"text\"]\n","test_b = pd.read_csv(\"test-b.texts\", sep=\"\\n\", header=None)\n","test_b.columns = [\"text\"]\n","\n","train[\"preprocessed text\"] = train[\"text\"].apply(preprocess)\n","test[\"preprocessed text\"] = test[\"text\"].apply(preprocess)\n","dev[\"preprocessed text\"] = dev[\"text\"].apply(preprocess)\n","test_b[\"preprocessed text\"] = test_b[\"text\"].apply(preprocess)\n","dev_b[\"preprocessed text\"] = dev_b[\"text\"].apply(preprocess)\n","\n","all_texts = pd.concat([train[\"preprocessed text\"], test[\"preprocessed text\"], dev[\"preprocessed text\"], test_b[\"preprocessed text\"], dev_b[\"preprocessed text\"]])\n","all_texts_splitted = list(map(lambda x: x.split(\" \"), all_texts))\n","\n","train_labels_txt = train[\"label\"].values\n","dev_labels_txt = dev[\"label\"].values\n","dev_b_labels_txt = dev_b[\"label\"].values\n","\n","test_b_txt = test_b[\"preprocessed text\"].values\n","train_txt = train[\"preprocessed text\"].values\n","dev_txt = dev[\"preprocessed text\"].values\n","test_txt = test[\"preprocessed text\"].values\n","dev_b_txt = dev_b[\"preprocessed text\"].values\n","\n","label_pipeline = lambda x: 1 if x == \"pos\" else 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHQ4Bs9QBr75"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)\n","MAX_LEN = 256"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"psOT9CsBBsGu"},"source":["from classifier_lr import UnsafeDataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6X2hL8JYB3BC"},"source":["train_dataset = classifier_lr.UnsafeDataset(tokenizer(train_txt.tolist(),\n","                                        max_length=64,\n","                                        truncation=True,\n","                                        padding='longest'), train_labels_txt.tolist())\n","\n","eval_dataset = classifier_lr.UnsafeDataset(tokenizer(dev_b_txt.tolist(),\n","                                       max_length=64,\n","                                       truncation=True,\n","                                       padding='longest'), dev_b_labels_txt.tolist())\n","\n","test_dataset = classifier_lr.UnsafeDataset(tokenizer(test_txt.tolist(),\n","                                       max_length=64,\n","                                       truncation=True,\n","                                       padding='longest'), test_b_txt.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8KEhnG6CGxo"},"source":["train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","eval_dataloader = DataLoader(eval_dataset, batch_size=16, shuffle=False)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WYkRR7VCG8e"},"source":["from classifier_lr import LogRegModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiAZ79VKCKDb"},"source":["vocab_size = tokenizer.vocab_size\n","n_classes = 2\n","emb_dim = 128\n","model = classifier_lr.LogRegModel(vocab_size, n_classes, emb_dim)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(torch.cuda.get_device_name())\n","else:\n","    print(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GvDqV6CuCKLk"},"source":["save_path = \"/content/drive/MyDrive/HW1/lr.pth\"\n","model = model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=2e-2)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruKEUax4CTYT"},"source":["from classifier_lr import train_model_epoch, val_model_epoch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"94kXlbABCTk7"},"source":["exp_name = datetime.now().isoformat(timespec='seconds')\n","writer = SummaryWriter(log_dir=f'logs/{exp_name}')\n","N_EPOCHS = 40\n","begin = 0\n","\n","for epoch in tqdm_notebook(range(N_EPOCHS)):\n","    print(\"training...\")\n","    loss, metrics, begin = classifier_lr.train_model_epoch(model, optimizer, criterion, train_dataloader, writer, begin)\n","    print(f\"training loss: {loss:.2e}\")\n","    print(\"evaluating...\")\n","    metrics = classifier_lr.val_model_epoch(model, eval_dataloader, writer)\n","    torch.save(model.state_dict(), save_path)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1jzlQgbCKYF"},"source":["metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FBr1YrxHfS25"},"source":["#### 2.1.2 Learning rate "]},{"cell_type":"markdown","metadata":{"id":"MhUmbNWRfS25"},"source":["Set up the learning rate equal to **1e-3**, regularizer coefficient of $L_2$ equal to  $\\alpha$=**1e-5**. Train logistic regression on train set. Build the plots for the loss function values and accuracies on train and validation sets during training.\n","\n","To plot this curves use matplotlib library ([very short](http://cs231n.github.io/python-numpy-tutorial/#matplotlib) и [not so very short](https://matplotlib.org/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) tutorials). Your may draw these plots in Jupyter notebook as well (see [example](http://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part\\%203\\%20-\\%20Plotting\\%20with\\%20Matplotlib.ipynb)). \n","\n","\n","_Question: plot the training curves. In how many epoch does yout algorithm converge? What accuracy do you get on train, dev and test sets? Do you observe underfitting or overfitting?_"]},{"cell_type":"markdown","metadata":{"id":"s3O0hySgXKy9"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"vT_kSgmofS2_"},"source":["Try to set different learning rates.\n","\n","*Question: Plot different training curves for different learning rate parameters. Which conclusions could be made on this?*"]},{"cell_type":"markdown","metadata":{"id":"ul-pY0QqXNAn"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"2xF6-PCCsH4_"},"source":["#### 2.1.3 Regularization "]},{"cell_type":"markdown","metadata":{"id":"iOpdGtKmfS2_"},"source":["For $\\alpha$ coefficient of $L_2$ regularizer we used a random value. Wrong/inappropriate $\\alpha$ causes underfitting ($\\alpha$ is too large) or overfitting ($\\alpha$ is too small). Choose the appropriate $\\alpha$ that helps to perform better on validation set. Be careful: $\\alpha$ changes the objective fiunction, so it is possible that the learning rate and the number of epochs should be changed too. Use plots to choose the appropriate values!\n","\n","_Question: plot training curves for several $\\alpha$ values. What conclusions could be made? How many epochs and which learning rate do you need until it converges? How long does it take to train and to label test data?_"]},{"cell_type":"markdown","metadata":{"id":"aM9j0g6rXW3p"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"IgE4ECCrfS3A"},"source":["### 2.2 Feed-forward Neural Network\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PHDXaWN1gE03"},"source":["The goal of this section to implement using **pytorch** a text categorization model using Feed-forward Neural Network. Following the steps below, you can complete corresponding parts in your ``classifier_ffnn.py`` script and apply the code for sentiment classification task."]},{"cell_type":"markdown","metadata":{"id":"Ztz0IxvlfS3A"},"source":["1. Repeat the steps 2.1.1 - 2.1.2 from the Logistic regression subsection."]},{"cell_type":"markdown","metadata":{"id":"sx_7FkZ1fS3B"},"source":["2. Implement Feed-forward Neural Network with **one** hidden layer using **pytorсh**."]},{"cell_type":"markdown","metadata":{"id":"Och_GenOfS3C"},"source":["3. Similarly to 2.1.10 and 2.1.11, do the finetuning for the learning rate and $\\alpha$ coefficient of $L_2$ regularizer hyperparameters on validation set.\n","\n","\n","_Question: plot learning curves for different $\\alpha$. What is the optimal value of $\\alpha$? of learning rate? How many epoch does it take to converge?_\n"]},{"cell_type":"markdown","metadata":{"id":"EZiHNzXIXcp4"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"WhdPPpt4fS3C"},"source":["Using $\\alpha$ and learning rate from 2.2.3 train the classifier on the whole train set. "]},{"cell_type":"markdown","metadata":{"id":"R2gqqo8kDW5x"},"source":["### 2.3 Recurrent Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"qUGiQQEZgSCE"},"source":["The goal of this section to implement using **pytorch** a text categorization model using Recurrent Neural Networks. Following the steps below, you can complete corresponding parts in your ``classifier_rnn.py`` script and apply the code for sentiment classification task. Choose between all proposed configuration that one that gives you the best validation score and implement it for the final submission."]},{"cell_type":"markdown","metadata":{"id":"_cHzm1wFCq7G"},"source":["#### 2.3.1 Use LSTM and word embeddings for text classification \n"]},{"cell_type":"markdown","metadata":{"id":"cCU1jduUfS3D"},"source":["Implement a text classifier based on Bi-LSTM network. Use hidden state(s) to represent an input text document.  If you use ``torch`` use the ``torch.nn.Embedding`` to load pre-trained word embeddings. Use the [GloVe](http://nlp.stanford.edu/data/wordvecs/glove.6B.zip) embeddings in the input layer of your network."]},{"cell_type":"markdown","metadata":{"id":"mYS2oBf4DsF0"},"source":["#### 2.3.2 Use LSTM and ELMo for text classification "]},{"cell_type":"markdown","metadata":{"id":"3LMbedVfDzhX"},"source":["Use ``allennlp`` and the model ``elmo_2x2048_256_2048cnn_1xhighway_weights`` which is the model used in week5 seminar to build a text classification system. The only difference from the previous point is the use of ELMo contextualized word embeddings. Do not use any additional dependencies or versions of the ELMo model. Make sure that the model is located in the same directory with the classification Python script."]},{"cell_type":"markdown","metadata":{"id":"UacyUcv0EReg"},"source":["#### 2.3.3 Use of document embeddings for text classification \n","\n"]},{"cell_type":"markdown","metadata":{"id":"SW4ciAlPEWA-"},"source":["Use ``gensim`` to obtain document embeddings for all reviews. Build a model based on logistic regression using ``sklearn`` which load these embeddings for each document and performs a classification. "]},{"cell_type":"markdown","metadata":{"id":"nqi0n32qpiap"},"source":["_Discuss: with which configuration have you achieved the best score? What was the results? What is your opinion -- why some model has performed worse and some better?_"]},{"cell_type":"markdown","metadata":{"id":"zBFkiHjlqFOy"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"Spc3M0zPofU1"},"source":["## 3. Research part"]},{"cell_type":"markdown","metadata":{"id":"_wurK7dBocDJ"},"source":["### 3.1 Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"STEuvCpQomKB"},"source":["Apart form classical gradient descent approach there are a lot of SGD variations, such as Adam, Adagrad, RMSProp, that are frequently used in the real-word cases. ([short](http://cs231n.github.io/neural-networks-3/#update) and [long](http://ruder.io/optimizing-gradient-descent/index.html#momentum) reviews on these approaches). The key thing about those approaches: apart from the gradients they use second derivative (momentum) for the next step.\n"]},{"cell_type":"markdown","metadata":{"id":"QYYaZhaXous6"},"source":["1. Implement Momentum or Adagrad and use it to train your logreg. Draw several plots for training with different hyperparameter values. What can be observed from the results and what conclusions could be made?"]},{"cell_type":"code","metadata":{"id":"iidj2Iq3CwZa"},"source":["def sgd_momentum(variables, gradients, config, state):  \n","    state.setdefault('accumulated_grads', {})\n","    \n","    var_index = 0 \n","    for current_layer_vars, current_layer_grads in zip(variables, gradients): \n","        for current_var, current_grad in zip(current_layer_vars, current_layer_grads):\n","            \n","            old_grad = state['accumulated_grads'].setdefault(var_index, np.zeros_like(current_grad))\n","            \n","            np.add(config['momentum'] * old_grad, config['learning_rate'] * current_grad, out=old_grad)\n","            \n","            current_var -= old_grad\n","            var_index += 1 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1p9vRy_jfS3D"},"source":["2. In order to improve classification  performance it is important to understand why and where the classifier makes mistakes. Find some examples, define, which features lead to the errors (e.g., in positive reviews $w^Tx_{\\{i\\}}$ they are used with mostly negative weights making the scalar product negative and wrong classification as the result). Are there any common features or tendencies in the errors found? If so, tell which steps could be made to improve the classifier?"]},{"cell_type":"markdown","metadata":{"id":"_RoFWLWDXhrX"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"evbtLCcbfS3D"},"source":["3. As bag-of-word vector component other different features may be used: absolute word counts, relative counts, binary features (whether the word appears in text), etc. We can transform each feature somehow: take logarithm, transform that each feature would belong to the [0, 1] range or normalize (substract mean value and divide by std). Try different approaches and describe the results."]},{"cell_type":"markdown","metadata":{"id":"MrBkXOSNXjXj"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"UkbceaTsfS3E"},"source":["### 3.2 Feed-forward Neural Network"]},{"cell_type":"markdown","metadata":{"id":"hQ8XOgnifS3E"},"source":["1. Try to improve your neural classifier performance expermenting with model architecture (change number of layers and their sizes). Draw the training curves (loss and accuracy) showing dependency of 1) layer size 2) number of layers. According to your experiments, which structure should be considered as the most efficient?"]},{"cell_type":"markdown","metadata":{"id":"uLgIc5FuXlXI"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"qbmOuCNDfS3E"},"source":["2. Try other gradient descent algorithms to your model (e.g. Adam, Adagrad, RMSProp)."]},{"cell_type":"markdown","metadata":{"id":"fnVWrAgCXnOZ"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"GAMaMjZeE8lH"},"source":["### 3.4 Recurrent Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"eN0XbQ_yFBnE"},"source":["#### 3.4.1 Different types of embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"_FaKMjiHFMKI"},"source":["Compare performance of [GloVe](http://nlp.stanford.edu/data/wordvecs/glove.6B.zip), [word2vec](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing) models to the model which has randomly initialized embedding layer (no pre-traied embeddings are used). Plot the results depending on the type of used embeddings. "]},{"cell_type":"markdown","metadata":{"id":"YgF73jHvXpsJ"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER \n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"Rd4fYOwUFQCb"},"source":["#### 3.4.2 Impact of hyper-parameter choice"]},{"cell_type":"markdown","metadata":{"id":"0FY2SzSaFaKS"},"source":["Try different numbers of hidden layers, LSTM cells used in each layers, learning rates, and other meta-parameters. Present plots which demonstrate performance of the model depending of values of these meta-parameters. Does bi-directional LSTM works better than uni-directioanl LSTM for this task? \n"]},{"cell_type":"markdown","metadata":{"id":"pkIDpKrhIAVx"},"source":["```\n","\n","PLEASE ENTER HERE YOUR ANSWER\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"ne0qSgQgNzui"},"source":["## 4. Bonus practical part: using BERT for text categorization\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KM2samVMN4i9"},"source":["This additional task can yield you extra points. In this task, you will need to create a sentiment text categorization model using a transformer-based pre-trained language model such BERT, ELECTRA, RoBERTa, etc. \n","\n","To complete the task you need to complate two tasks below.\n"]},{"cell_type":"markdown","metadata":{"id":"k8k5CNKwOcXM"},"source":["###4.1 Text classifier"]},{"cell_type":"markdown","metadata":{"id":"1M1EnMoiOjJC"},"source":["Write in the cell below the complete executable code of your solution (you do not need to provide the ``classifier.py`` script in this case. "]},{"cell_type":"markdown","metadata":{"id":"JL_IKEIZeZA1"},"source":["1. Please enter your code below.\n","2. Perform the required downloads of the data for training of the model and generation of the TSV file.\n","3. Your model has to be trained and generate the file for the Colab susbmission."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mB723QYtvZD3","executionInfo":{"status":"ok","timestamp":1621896974090,"user_tz":-180,"elapsed":23251,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"c7badc77-662c-4cf0-8153-0c5a850ff52a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rxEEaKbvgv4","executionInfo":{"status":"ok","timestamp":1621896983969,"user_tz":-180,"elapsed":9896,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"fc38d4fa-54b8-4138-88fb-8cf743886003"},"source":["!wget https://github.com/skoltech-nlp/filimdb_evaluation/raw/master/FILIMDB.tar.gz\n","!tar -zxvf FILIMDB.tar.gz\n","!mv -t . FILIMDB/*\n","!rm -rf FILIMDB\n","!pip install transformers -qq"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-24 22:56:13--  https://github.com/skoltech-nlp/filimdb_evaluation/raw/master/FILIMDB.tar.gz\n","Resolving github.com (github.com)... 192.30.255.113\n","Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/skoltech-nlp/filimdb_evaluation/master/FILIMDB.tar.gz [following]\n","--2021-05-24 22:56:13--  https://raw.githubusercontent.com/skoltech-nlp/filimdb_evaluation/master/FILIMDB.tar.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 53759460 (51M) [application/octet-stream]\n","Saving to: ‘FILIMDB.tar.gz’\n","\n","FILIMDB.tar.gz      100%[===================>]  51.27M   102MB/s    in 0.5s    \n","\n","2021-05-24 22:56:15 (102 MB/s) - ‘FILIMDB.tar.gz’ saved [53759460/53759460]\n","\n","FILIMDB/\n","FILIMDB/train.labels\n","FILIMDB/train_unlabeled.texts\n","FILIMDB/test.texts\n","FILIMDB/train.texts\n","FILIMDB/dev.labels\n","FILIMDB/dev.texts\n","FILIMDB/dev-b.labels\n","FILIMDB/dev-b.texts\n","FILIMDB/test-b.texts\n","\u001b[K     |████████████████████████████████| 2.3MB 7.8MB/s \n","\u001b[K     |████████████████████████████████| 901kB 48.3MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 40.9MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ar6uj4ehLQ6c"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, precision_score, recall_score, f1_score\n","from torchtext.data.utils import get_tokenizer\n","from collections import Counter\n","from torchtext.vocab import Vocab\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch import optim\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm as tqdm_notebook\n","from tqdm import tqdm\n","from IPython.display import display, clear_output\n","from datetime import datetime\n","from torch.utils.tensorboard import SummaryWriter\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","from typing import List, Any\n","from time import time\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","import nltk\n","from nltk.corpus import wordnet\n","from nltk.stem import WordNetLemmatizer\n","import transformers\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ekB1MQZyvg4S","executionInfo":{"status":"ok","timestamp":1621896990950,"user_tz":-180,"elapsed":644,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"b09fef24-1650-4196-81e8-dbea05efbc02"},"source":["nltk.download('wordnet')\n","nltk.download('stopwords')\n","\n","wordnet_lemmatizer = WordNetLemmatizer()\n","tokenizer = RegexpTokenizer(r'[a-z]+')\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess(document):\n","    document = document.lower()   \n","    words = tokenizer.tokenize(document)   \n","    words = [w for w in words if w not in stop_words]    \n","    for pos in [wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV]:    \n","        words = [wordnet_lemmatizer.lemmatize(x, pos) for x in words]\n","    return \" \".join(words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2-vxBoFNvhB-"},"source":["train_texts = pd.read_csv(\"train.texts\", sep=\"\\n\", header=None)\n","train_labels = pd.read_csv(\"train.labels\", sep=\"\\n\", header=None)\n","train = pd.concat([train_texts, train_labels], ignore_index=True, axis=1)\n","train.columns = [\"text\", \"label\"]\n","\n","dev_texts = pd.read_csv(\"dev.texts\", sep=\"\\n\", header=None)\n","dev_labels = pd.read_csv(\"dev.labels\", sep=\"\\n\", header=None)\n","dev = pd.concat([dev_texts, dev_labels], ignore_index=True, axis=1)\n","dev.columns = [\"text\", \"label\"]\n","\n","dev_b_texts = pd.read_csv(\"dev-b.texts\", sep=\"\\n\", header=None)\n","dev_b_labels = pd.read_csv(\"dev-b.labels\", sep=\"\\n\", header=None)\n","dev_b = pd.concat([dev_b_texts, dev_b_labels], ignore_index=True, axis=1)\n","dev_b.columns = [\"text\", \"label\"]\n","\n","test = pd.read_csv(\"test.texts\", sep=\"\\n\", header=None)\n","test.columns = [\"text\"]\n","test_b = pd.read_csv(\"test-b.texts\", sep=\"\\n\", header=None)\n","test_b.columns = [\"text\"]\n","\n","train[\"preprocessed text\"] = train[\"text\"].apply(preprocess)\n","test[\"preprocessed text\"] = test[\"text\"].apply(preprocess)\n","dev[\"preprocessed text\"] = dev[\"text\"].apply(preprocess)\n","test_b[\"preprocessed text\"] = test_b[\"text\"].apply(preprocess)\n","dev_b[\"preprocessed text\"] = dev_b[\"text\"].apply(preprocess)\n","\n","all_texts = pd.concat([train[\"preprocessed text\"], test[\"preprocessed text\"], dev[\"preprocessed text\"], test_b[\"preprocessed text\"], dev_b[\"preprocessed text\"]])\n","all_texts_splitted = list(map(lambda x: x.split(\" \"), all_texts))\n","\n","train_labels_txt = train[\"label\"].values.tolist()\n","dev_labels_txt = dev[\"label\"].values.tolist()\n","dev_b_labels_txt = dev_b[\"label\"].values.tolist()\n","\n","test_b_txt = test_b[\"preprocessed text\"].values.tolist()\n","train_txt = train[\"preprocessed text\"].values.tolist()\n","dev_txt = dev[\"preprocessed text\"].values.tolist()\n","test_txt = test[\"preprocessed text\"].values.tolist()\n","dev_b_txt = dev_b[\"preprocessed text\"].values.tolist()\n","\n","label_pipeline = lambda x: 1 if x == \"pos\" else 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I6xo6p1uvyhl","colab":{"base_uri":"https://localhost:8080/","height":165,"referenced_widgets":["8eb25c55a2194680983303952647c2b9","dc994f5c2eb54f15a48d1b1a01dc6891","b0846496b4d8457f87146a8d93b17b8a","ec58710d058647f0a40c940bde4b554d","8483068278d0450ea331fac08be9982c","06dbd36066a94cb48ab46bce7d976d0c","deadb8fa5ff943eca8a97c57a34225cf","ec658138b17d4af2ad7814794d5a32ef","06fa647778a645a6b589c7d597dc0c5a","046461c20b074323a5c733692eaa14e5","5e41ef62750d47a6ad3ec8f21cbc5da4","8f53c9eb41794c30a155f4ead6ef7278","7dcd0530686a4f95b8da53025dc66ab8","2b9ef777620d41cdad1be8a9515d7b8f","6cd1230b18824cd5bdf5bbed69be138a","786f3c1670be43f9996fd1d8419e1476","a1ec235711794ef48f8ca9b227a9c987","6490ccbc7c85427287cbcee4a343e1d2","b1b0dfe0d096475baaeea9dc1171b455","7aa65b5992bb41b5b58a2d34de9cfdc3","3f3c0b3bdd8341ce9a5d0ac987d2d91b","30f76aee837d4b52b7615c8d0ea87bbe","e07475c28d1a41ed9a9852701fd4cc73","987258ae0815412b8e545c29a7d7e11d"]},"executionInfo":{"status":"ok","timestamp":1621897067519,"user_tz":-180,"elapsed":2391,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"3cfe85a4-2a8d-4566-e558-e4c9ed1a0783"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)\n","MAX_LEN = 256"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8eb25c55a2194680983303952647c2b9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06fa647778a645a6b589c7d597dc0c5a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1ec235711794ef48f8ca9b227a9c987","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189,"referenced_widgets":["689b7e047d5f429cbdf2a256835401ac","be7ba71d841041fd89244d99a1b5cd1e","627b57e509434d27bb0e2e40131f46c5","10fdbca389694ccdb213092e6e1a9140","f3048431aa6d4939b370e5e89ac57290","31f25f5dca2844c7a2254a90f2af02a3","86905f8e926b47959476f2fd89db4886","38566b1c5b5b45da9d29fae9d515b77b","19da1eca3c0a4a6085d2a5c5557a9e4a","b5f4e7fb50c4475ca4a8fd6ce4a2489e","0521deb5da764e1881a011f98fb08b51","a8afaf55772743afa5fcd2369f4808a1","049bad6301b642f2abb4d5e8c25f79f0","5c9b4aefd9b64bc9ac28f0ddcf39baac","774a3a0f6a1d4a8399a554151a42a2f0","e64d5415da1549e481adf7832dc1a7e9"]},"id":"EB9HfmvfwKdu","executionInfo":{"status":"ok","timestamp":1621897118419,"user_tz":-180,"elapsed":50912,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"101d97a7-64e1-403b-bfb3-f991dd83ecab"},"source":["class BertData(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        super(BertData, self).__init__()\n","        ids, masks = [], []\n","        for txt in tqdm_notebook(texts):\n","            encoding = tokenizer.encode_plus(\n","                txt,\n","                add_special_tokens=True,\n","                max_length=max_len,\n","                return_token_type_ids=False,\n","                pad_to_max_length=True,\n","                return_attention_mask=True,\n","                return_tensors='pt',\n","            )\n","            ids.append(encoding[\"input_ids\"])\n","            masks.append(encoding[\"attention_mask\"])\n","        self.ids = torch.cat(ids, dim=0)\n","        self.masks = torch.cat(masks, dim=0)\n","        if labels is not None:\n","            self.target = torch.LongTensor([label_pipeline(token) for token in labels])\n","\n","    def __getitem__(self, item):\n","        return {\n","            \"input_ids\": self.ids[item],\n","            \"attention_mask\": self.masks[item],\n","            \"target\": self.target[item]}\n","\n","    def __len__(self):\n","        return self.ids.shape[0]\n","    \n","train_data = BertData(train_txt, train_labels_txt, tokenizer, MAX_LEN)\n","val_data = BertData(dev_b_txt, dev_b_labels_txt, tokenizer, MAX_LEN)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"689b7e047d5f429cbdf2a256835401ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19da1eca3c0a4a6085d2a5c5557a9e4a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2dz1yNWwRHg","executionInfo":{"status":"ok","timestamp":1621897118420,"user_tz":-180,"elapsed":22,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"cddfc1b7-b2fc-472b-b79a-2c921e226e45"},"source":["train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n","val_dataloader = DataLoader(val_data, batch_size=16, shuffle=True)\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(torch.cuda.get_device_name(0))\n","else:\n","    print(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBRrSgQqwRV2"},"source":["class SentimentModel(nn.Module):\n","    def __init__(self, hid_size=768):\n","        super(SentimentModel, self).__init__()\n","        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n","        self.dropout = nn.Dropout(0.1)\n","        self.fc = nn.Linear(hid_size, 2)\n","\n","    def forward(self, input_ids, attention_mask):\n","        x = self.bert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","        )[1]\n","        x = self.dropout(x)\n","        logits = self.fc(x)\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":189,"referenced_widgets":["2dd5bce069174241b53c01cd8d532661","540fb260e7644976b2be41677bfc2023","4aa373c58c6a47a5a2702d20047931bc","ef05c9246e7e4777ad0f5f70ad473bc8","5fdcbc6876014ab7bf326cb3ca3bedc8","2818a5751fe347809e2b6e8ed07d705b","6d75f8de83dc4edf90ce5c1ba977f7c6","1a894d0f733c47f59929a2e91b18c67f","8ad7408896454b0881ed8f66f7ef5f58","32834375a8c142848de1404b4c34fbe4","d0d880bea7404d36a7208f5faac1f9a7","0428664838bb4cd3adf754e11c672305","39b76bd8a84343058972da34a7c28da2","bc5d4ed72d7c45f89c1f430cb52ea81f","873f7c192db6404a885d52e47bcd604e","d2577a60212a4f7facc48ba9ec080580"]},"id":"haU12QkUwKlu","executionInfo":{"status":"ok","timestamp":1621897140485,"user_tz":-180,"elapsed":22082,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"cb2de372-acfa-4991-c445-a0d87e7897d9"},"source":["N_EPOCHS = 3\n","LR = 5e-6\n","model = SentimentModel()\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","\n","optimizer = AdamW(model.parameters(), lr=LR, correct_bias=False)\n","total_steps = len(train_dataloader) * N_EPOCHS\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dd5bce069174241b53c01cd8d532661","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ad7408896454b0881ed8f66f7ef5f58","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":733,"referenced_widgets":["f0e2dfc596a14658b586153d7054247f","0fbd353e3af049d890343024ac7cf456","34ae3b4d139b4093a72e285fb4f7d006","847610221aef4bddab24d211055de585","d7b6e6e438b442e580daeba5447263e0","4026fe04366942c796eb49ebce34375d","8298015056da465a83e945f27e2cd48a","1beebd7bf5814fc1b403d91ca9e96ac8","dce71090493c401c9fe17bcd01a539b2","aadd501b17a44e2c90d2d5be91720d8d","8074c803a9ce4300bc0a7da1dfa5023a","bca3ca4996dc45cf8fb59e3b0f60aa1d","7e68e59c63584d098885a64d5a77477c","60285a04255348aa91233d26a6409371","71c51a1271a541418a387117efa833da","7b0d4b39d8cd43e6ab336c83c4697973","5d86af192b2f46ff89dc05c8ba9eb4c7","a632ffafb5e140af994478d05c19a0bd","0affee597f2e4cc8ba54455acda19248","dce4cf683f084356b4570e80e25023d3","29feb1fe24b947b8b883d65e5e1ab808","e4c0ecffe7ca48e994fd5992157e96fa","ab52381f8eea4e6b86ce047e8ea3e6be","a0330ff1af93463e8dc121fe7a5e5e91","64274f32726d454e8f9339d21f011e6e","80d21c397e90481683d639c02621c051","5431e1d8a6844a2eb21987ea2d9b4f49","a60a937800ef4dd7a26c7bcd1926dfd3","d9f12c5336e9423b8a566e27b8bfc7d5","cae000767a024627b1bda75aae149aec","c64eeecf6e2048368563947a158c7578","449d10b16bb24a1c8f35aa9a5986b10a","f26af7ae9f42419f9d510f94e26f335e","befe0974b2244259b787a35b5365f937","7383533c71064302aca9210b4561bb71","5de2f03a5bce4f0f8893014acc26a76b","80e80f3873844f58b0e5bf4672ecbf82","4ccdbde08cd24bd5ab267e74dbd16927","d1ca93a6d0e842fb8d5bc6c83a7088b7","d43eaeb26e7f4e92bf19bbeaae0bd6d7","da6bb8f21e7e4d589bc3c709848b234a","17ba518751314284bb04f0a3ce74257f","a42a72b55b454c029d8f00e250f88e39","b5c7bc610e9c4f299b659ea3b9be6d2e","daef4695c654419fb59b15cc7342002f","c61f900db1004570bd685bc7b7b01552","d144952b8b3849daa61131f50a003d8e","d7d29f1f69be47828751b797f1047041","bf376ede7fe04c32bbc92a5c806303f9","222c665f612146afb2a21162759d1f8c","73274d31b6de46f8ada77c614a07c240","81541e6f2f74473fad55967d94f098c8","90cc5b0ef98d4b0db4946d53e2e6722d","acd2adb229ac48e2a268563dfc8505a3","27cb848d7e294bff8b51bcef634c8e14","733dd3195fd0434d96e770a50e9df36d"]},"id":"p60S0Llqwa0e","executionInfo":{"status":"ok","timestamp":1621899320614,"user_tz":-180,"elapsed":2180139,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"c8b185bc-8df7-4e0a-9cfe-bebaee484a1d"},"source":["exp_name = datetime.now().isoformat(timespec='seconds')\n","writer = SummaryWriter(log_dir=f'logs/{exp_name}')\n","save_path = \"/content/drive/MyDrive/HW1/bert.pth\"\n","\n","train_loss_log = []\n","train_acc_log = []\n","val_acc_log = []\n","train_loss_total = []\n","step = 0\n","for epoch in tqdm_notebook(range(N_EPOCHS)):\n","    model.train()\n","    train_loss = 0\n","    train_acc = 0\n","    print(f\"Epoch {epoch}\")\n","    print(\"Training...\")\n","    for batch in tqdm_notebook(train_dataloader):\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        input_ids = batch[\"input_ids\"].to(device)\n","        target = batch[\"target\"].to(device)\n","        optimizer.zero_grad()\n","        logits = model(input_ids, attention_mask)\n","        out = F.log_softmax(logits, dim=1)\n","        loss = criterion(logits, target)\n","        pred = out.cpu().detach().argmax(1)\n","        train_loss += loss.item()\n","        train_acc += torch.sum(pred == target.cpu().detach()).item()\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        train_loss_total.append(loss.item())\n","        writer.add_scalar('Loss/total', loss.item(), step)\n","        step += 1\n","\n","    train_loss_log.append(train_loss / len(train_dataloader))\n","    train_acc_log.append(train_acc / len(train_dataloader.dataset))\n","\n","    model.eval()\n","    val_acc = 0\n","    print(\"evaluating...\")\n","    for batch in tqdm_notebook(val_dataloader):\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        input_ids = batch[\"input_ids\"].to(device)\n","        target = batch[\"target\"].to(device)\n","        logits = model(input_ids, attention_mask)\n","        out = F.log_softmax(logits, dim=1)\n","        pred = out.cpu().detach().argmax(1)\n","        val_acc += torch.sum(pred == target.cpu().detach()).item()\n","    val_acc_log.append(val_acc / len(val_dataloader.dataset))\n","\n","    torch.save({\n","        \"model_state_dict\": model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, save_path)\n","    writer.add_scalar('Loss/train', train_loss_log[-1], epoch)\n","    writer.add_scalar('Accuracy/train', train_acc_log[-1], epoch)\n","    writer.add_scalar('Accuracy/val', val_acc_log[-1], epoch)\n","    print(f'Loss/train: {train_loss_log[-1]:.2f}')\n","    print(f'Accuracy/train: {train_acc_log[-1]:.2f}')\n","    print(f'Accuracy/val: {val_acc_log[-1]:.2f}')\n","    print(f\"Saved to {save_path}\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0e2dfc596a14658b586153d7054247f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 0\n","Training...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dce71090493c401c9fe17bcd01a539b2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=938.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","evaluating...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d86af192b2f46ff89dc05c8ba9eb4c7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Loss/train: 0.36\n","Accuracy/train: 0.84\n","Accuracy/val: 0.74\n","Saved to /content/drive/MyDrive/HW1/bert.pth\n","Epoch 1\n","Training...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64274f32726d454e8f9339d21f011e6e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=938.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","evaluating...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f26af7ae9f42419f9d510f94e26f335e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Loss/train: 0.24\n","Accuracy/train: 0.91\n","Accuracy/val: 0.75\n","Saved to /content/drive/MyDrive/HW1/bert.pth\n","Epoch 2\n","Training...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da6bb8f21e7e4d589bc3c709848b234a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=938.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","evaluating...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf376ede7fe04c32bbc92a5c806303f9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Loss/train: 0.20\n","Accuracy/train: 0.93\n","Accuracy/val: 0.76\n","Saved to /content/drive/MyDrive/HW1/bert.pth\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLtJyoiEwa64","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1621899321267,"user_tz":-180,"elapsed":674,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"1541bfa5-c038-469c-8c4c-79f56e20cfc0"},"source":["plt.plot(train_acc_log)\n","plt.plot(val_acc_log)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f2213a6aad0>]"]},"metadata":{"tags":[]},"execution_count":17},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"GRzSUaTTwjY4","colab":{"base_uri":"https://localhost:8080/","height":320,"referenced_widgets":["153ed73a1dd44380be2a0e83f648aaab","57a126f2767249a0b6893b41cc2253d5","d4e0bcfc8c824cac93fa3926be259fa5","971c12d11c4c46f0b174d73e5c9ed2f8","bbcba3390fc44911bd9833c83467fe53","5f9a233085684e50808d33376256cfac","70fd75d27f9944c4948188f63155a114","42aab79807dc4d669d6086f81f51d69b","e5e68d9a912c4742a7fd3256f4b4cd18","39f7cb29cfd64b69b017e27121c404e6","542634377d8042f08d233f38ddbd22d9","ccfd5b020ecb43f4b165440ae3c6f6f7","e4e9496ca5834c85a02d9eaa3a7bf83f","916369227dd84fbb91f616f5e10e8227","68f28144f0f64642b7ad5d0c100a2bc3","9bb59ed3da924660a827a962df394370","912e7132af704963b3024cf8f9be30d2","3236f13d41754856b885b91145d3bab8","32c44d494cca4a0693c7af07b309482a","b2c9709b84394ca8ab1e197051489dbc","3da58656f2364662ac44bbe463af1564","f67ab1078e004b65912d9c3aed7c6768","285cfaa5221e47afa8eba3bad722bf67","86db312260654a5a80a156eb91afc03f","69735f31b9c4440fac68f50f61a1bb22","713017c87a4a4895a9d94c3f8ae46348","75b97422710146c09cc0fbab7ac5bb7c","e37eb2f58b5c4d3d858b53982dd176cd","ba61c6a6061843d3b02484bb66be1dab","e4c40d2f950c4937bba3c220bb25accc","2ce334302b2e4bc494f9ac056f6c5194","3e5c4e104a944723a3012d35992e02dd","b401ea0ce357410888563a7da0d468e2","09a9451b9b8b41f08253356be7f4fc05","ce75df1b84744566b067f58e78df5a25","27b7a81d9b7e4db3b9952ab7fbe15949","d15f8544a1d944b0a0ce90674fc11eb6","1ec2e1037cf74ff3aea7d540540997c2","ecaa2a8a030a4177b2c8b9e6214ece57","69280274a9a74fc69ca8e021b3e0502b"]},"executionInfo":{"status":"ok","timestamp":1621900539338,"user_tz":-180,"elapsed":1218083,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"911b81e4-b1a8-4c15-9ece-f864ce1420ba"},"source":["names = [\"train\", \"dev\", \"test\", \"dev-b\", \"test-b\"]\n","datasets = [train, dev, test, dev_b, test_b]\n","index = []\n","predictions = []\n","\n","checkpoint = torch.load(save_path)\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","model.eval()\n","for name, dataset in zip(names, datasets):\n","    for idx in tqdm_notebook(range(dataset.shape[0])):\n","        txt = dataset.iloc[idx][\"preprocessed text\"]\n","        encoding = tokenizer.encode_plus(\n","            txt,\n","            add_special_tokens=True,\n","            max_length=MAX_LEN,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","        input_ids = encoding[\"input_ids\"].to(device)\n","        attention_mask = encoding[\"attention_mask\"].to(device)\n","        logits = model(input_ids, attention_mask)\n","        pred = F.softmax(logits, dim=1).cpu().detach().argmax(1).item()\n","        pred_str = \"neg\" if pred == 0 else \"pos\"\n","        predictions.append(pred_str)\n","    \n","    index.extend([f\"{name}/{i}\" for i in range(len(dataset))])\n","results = pd.DataFrame({0: index, 1: predictions})"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"153ed73a1dd44380be2a0e83f648aaab","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=15000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5e68d9a912c4742a7fd3256f4b4cd18","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"912e7132af704963b3024cf8f9be30d2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69735f31b9c4440fac68f50f61a1bb22","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b401ea0ce357410888563a7da0d468e2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=8599.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gFrlvtoBvyre","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621900539740,"user_tz":-180,"elapsed":417,"user":{"displayName":"Kundyz Onlabek","photoUrl":"","userId":"08607157923011124884"}},"outputId":"9f02fec6-0cca-4ac2-a788-077091ba1aa6"},"source":["results.to_csv(\"bert_results.tsv\", sep=\"\\t\", index=False, header=False)\n","!zip -FS bert_results.zip bert_results.tsv\n","!cp -t /content/drive/MyDrive/HW1 bert_results.zip bert_results.tsv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  adding: bert_results.tsv (deflated 82%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XAqWFQOkO8zy"},"source":["###4.2 Submission to Colab\n"]},{"cell_type":"markdown","metadata":{"id":"P3Uz9crUPAxq"},"source":["Upload the file to Codalab. Write below how it compared to scores of your submissions with simpler models in this assignment (LR, FFNN, RNN). "]},{"cell_type":"markdown","metadata":{"id":"_Ru9EkPzDd40"},"source":["kundyz_onlabek"]}]}